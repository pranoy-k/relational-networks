{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIPS Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import json\n",
    "from os.path import isfile, isdir\n",
    "import wget\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Process the DataSet\n",
    "\n",
    "### 1.1 Download the Dataset\n",
    "> Download the dataset from [CLEVR](https://s3-us-west-1.amazonaws.com/clevr/CLEVR_v1.0.zip) manually or run the following cell.\n",
    "\n",
    "Beware it can take up almost 18GB of your diskspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/user/kpranoy/relational-networks\n"
     ]
    }
   ],
   "source": [
    "cd relational-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Downloading the dataset, Makesure your directory is the root of the Project\n",
    "\n",
    "data_zip_file = \"CLEVR_v1.0.zip\"\n",
    "DataDir = \"data/CLEVR_v1.0/\"        \n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "if not isfile(data_zip_file):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CLEVR dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://s3-us-west-1.amazonaws.com/clevr/CLEVR_v1.0.zip',\n",
    "            data_zip_file,\n",
    "            pbar.hook)\n",
    "        \n",
    "if not isdir(DataDir):\n",
    "    with zipfile.ZipFile(data_zip_file,\"r\") as zip_ref:\n",
    "        zip_ref.extractall(DataDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Curating the Dataset and getting the statistics **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Train Images: 70000 , Test Images: 15000 , Val Images: 15000\n"
     ]
    }
   ],
   "source": [
    "## Counting the number of images in Train, Test and Val \n",
    "\n",
    "train_images = os.listdir (DataDir + \"/images/train/\")\n",
    "test_images = os.listdir (DataDir + \"/images/test/\")\n",
    "val_images = os.listdir (DataDir + \"/images/val/\")\n",
    "\n",
    "print(\"The number of Train Images: {} , Test Images: {} , Val Images: {}\".format(len(train_images),len(test_images),len(val_images)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading the question and Answers from the JSon files \n",
    "with open((DataDir + \"/questions/CLEVR_train_questions.json\"), 'r') as f:\n",
    "    train_questions = json.load(f)\n",
    "with open((DataDir + \"/questions/CLEVR_test_questions.json\"), 'r') as f:\n",
    "    test_questions = json.load(f)\n",
    "with open((DataDir + \"/questions/CLEVR_val_questions.json\"), 'r') as f:\n",
    "    val_questions = json.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Train Questions: 699989 , Test Questions: 149988 , Val Images: 149991\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of Train Questions: {} , Test Questions: {} , Val Images: {}\".format(\n",
    "    len(train_questions['questions']),\n",
    "    len(test_questions ['questions']),\n",
    "    len(val_questions  ['questions'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking around One of the question to understand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'yes',\n",
       " 'image_filename': 'CLEVR_train_000000.png',\n",
       " 'image_index': 0,\n",
       " 'program': [{'function': 'scene', 'inputs': [], 'value_inputs': []},\n",
       "  {'function': 'filter_size', 'inputs': [0], 'value_inputs': ['large']},\n",
       "  {'function': 'filter_color', 'inputs': [1], 'value_inputs': ['green']},\n",
       "  {'function': 'count', 'inputs': [2], 'value_inputs': []},\n",
       "  {'function': 'scene', 'inputs': [], 'value_inputs': []},\n",
       "  {'function': 'filter_size', 'inputs': [4], 'value_inputs': ['large']},\n",
       "  {'function': 'filter_color', 'inputs': [5], 'value_inputs': ['purple']},\n",
       "  {'function': 'filter_material', 'inputs': [6], 'value_inputs': ['metal']},\n",
       "  {'function': 'filter_shape', 'inputs': [7], 'value_inputs': ['cube']},\n",
       "  {'function': 'count', 'inputs': [8], 'value_inputs': []},\n",
       "  {'function': 'greater_than', 'inputs': [3, 9], 'value_inputs': []}],\n",
       " 'question': 'Are there more big green things than large purple shiny cubes?',\n",
       " 'question_family_index': 2,\n",
       " 'question_index': 0,\n",
       " 'split': 'train'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions['questions'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the dataset we need to process the questions and the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'fish'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-0f2b0bf445ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfish\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named 'fish'"
     ]
    }
   ],
   "source": [
    "import fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
